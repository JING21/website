"use strict";(self.webpackChunk_project_hami_website=self.webpackChunk_project_hami_website||[]).push([[3217],{3905:(e,n,t)=>{t.d(n,{Zo:()=>u,kt:()=>c});var a=t(7294);function r(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function o(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);n&&(a=a.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,a)}return t}function l(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?o(Object(t),!0).forEach((function(n){r(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):o(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function s(e,n){if(null==e)return{};var t,a,r=function(e,n){if(null==e)return{};var t,a,r={},o=Object.keys(e);for(a=0;a<o.length;a++)t=o[a],n.indexOf(t)>=0||(r[t]=e[t]);return r}(e,n);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(a=0;a<o.length;a++)t=o[a],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(r[t]=e[t])}return r}var i=a.createContext({}),p=function(e){var n=a.useContext(i),t=n;return e&&(t="function"==typeof e?e(n):l(l({},n),e)),t},u=function(e){var n=p(e.components);return a.createElement(i.Provider,{value:n},e.children)},d={inlineCode:"code",wrapper:function(e){var n=e.children;return a.createElement(a.Fragment,{},n)}},m=a.forwardRef((function(e,n){var t=e.components,r=e.mdxType,o=e.originalType,i=e.parentName,u=s(e,["components","mdxType","originalType","parentName"]),m=p(t),c=r,k=m["".concat(i,".").concat(c)]||m[c]||d[c]||o;return t?a.createElement(k,l(l({ref:n},u),{},{components:t})):a.createElement(k,l({ref:n},u))}));function c(e,n){var t=arguments,r=n&&n.mdxType;if("string"==typeof e||r){var o=t.length,l=new Array(o);l[0]=m;var s={};for(var i in n)hasOwnProperty.call(n,i)&&(s[i]=n[i]);s.originalType=e,s.mdxType="string"==typeof e?e:r,l[1]=s;for(var p=2;p<o;p++)l[p]=t[p];return a.createElement.apply(null,l)}return a.createElement.apply(null,t)}m.displayName="MDXCreateElement"},7029:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>i,contentTitle:()=>l,default:()=>d,frontMatter:()=>o,metadata:()=>s,toc:()=>p});var a=t(7462),r=(t(7294),t(3905));const o={title:"Performance Test Setup for Karmada"},l=void 0,s={unversionedId:"developers/performance-test-setup-for-karmada",id:"developers/performance-test-setup-for-karmada",title:"Performance Test Setup for Karmada",description:"Abstract",source:"@site/docs/developers/performance-test-setup-for-karmada.md",sourceDirName:"developers",slug:"/developers/performance-test-setup-for-karmada",permalink:"/zh/docs/next/developers/performance-test-setup-for-karmada",draft:!1,editUrl:"https://github.com/karmada-io/website/edit/main/docs/developers/performance-test-setup-for-karmada.md",tags:[],version:"current",lastUpdatedBy:"limengxuan",lastUpdatedAt:1713177637,formattedLastUpdatedAt:"2024\u5e744\u670815\u65e5",frontMatter:{title:"Performance Test Setup for Karmada"},sidebar:"docs",previous:{title:"Profiling Karmada",permalink:"/zh/docs/next/developers/profiling-karmada"},next:{title:"How to contribute docs",permalink:"/zh/docs/next/contributor/contribute-docs"}},i={},p=[{value:"Abstract",id:"abstract",level:2},{value:"Build large scale environment",id:"build-large-scale-environment",level:2},{value:"Create member clusters using kind",id:"create-member-clusters-using-kind",level:3},{value:"Why kind",id:"why-kind",level:4},{value:"Usage",id:"usage",level:4},{value:"Simulate a large number of fake nodes using fake-kubelet",id:"simulate-a-large-number-of-fake-nodes-using-fake-kubelet",level:3},{value:"Why fake-kubelet",id:"why-fake-kubelet",level:4},{value:"Compare to Kubemark",id:"compare-to-kubemark",level:5},{value:"Usage",id:"usage-1",level:4},{value:"Distribute resources using CLusterLoader2",id:"distribute-resources-using-clusterloader2",level:2},{value:"ClusterLoader2",id:"clusterloader2",level:3},{value:"Prepare a simple config",id:"prepare-a-simple-config",level:3},{value:"Start Distributing",id:"start-distributing",level:3},{value:"Monitor Karmada control plane using Prometheus and Grafana",id:"monitor-karmada-control-plane-using-prometheus-and-grafana",level:2},{value:"Deploy Prometheus and Grafana",id:"deploy-prometheus-and-grafana",level:3},{value:"Create Grafana DashBoards to observe Karmada control plane metrics",id:"create-grafana-dashboards-to-observe-karmada-control-plane-metrics",level:3},{value:"Create a dashboard",id:"create-a-dashboard",level:4},{value:"Modify Query Statement",id:"modify-query-statement",level:4}],u={toc:p};function d(e){let{components:n,...o}=e;return(0,r.kt)("wrapper",(0,a.Z)({},u,o,{components:n,mdxType:"MDXLayout"}),(0,r.kt)("h2",{id:"abstract"},"Abstract"),(0,r.kt)("p",null,"As Karmada is being implemented in more and more enterprises and organizations, scalability and scale of Karmada is gradually becoming new concerns for the community. In this article, we will introduce how to conduct large-scale testing for Karmada and how to monitor metrics from Karmada control plane."),(0,r.kt)("h2",{id:"build-large-scale-environment"},"Build large scale environment"),(0,r.kt)("h3",{id:"create-member-clusters-using-kind"},"Create member clusters using kind"),(0,r.kt)("h4",{id:"why-kind"},"Why kind"),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://sigs.k8s.io/kind"},"Kind")," is a tool for running local Kubernetes clusters using Docker containers. Kind was primarily designed for testing Kubernetes itself, so it play a good role in simulating member clusters."),(0,r.kt)("h4",{id:"usage"},"Usage"),(0,r.kt)("blockquote",null,(0,r.kt)("p",{parentName:"blockquote"},"Follow the ",(0,r.kt)("a",{parentName:"p",href:"https://kind.sigs.k8s.io/docs/user/quick-start#installation"},"kind installation")," guide.")),(0,r.kt)("p",null,"Create 10 member clusters:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-shell"},"for ((i=1; i<=10; i ++)); do\n    kind create cluster --name member$i\ndone;\n")),(0,r.kt)("h3",{id:"simulate-a-large-number-of-fake-nodes-using-fake-kubelet"},"Simulate a large number of fake nodes using fake-kubelet"),(0,r.kt)("h4",{id:"why-fake-kubelet"},"Why fake-kubelet"),(0,r.kt)("h5",{id:"compare-to-kubemark"},"Compare to Kubemark"),(0,r.kt)("p",null,(0,r.kt)("strong",{parentName:"p"},"Kubemark")," is directly implemented with the code of kubelet, replacing the runtime part, except that it does not actually start the container, other behaviors are exactly the same as kubelet, mainly used for Kubernetes own e2e test, simulating a large number of nodes and pods will ",(0,r.kt)("strong",{parentName:"p"},"occupy the same memory as the real scene"),"."),(0,r.kt)("p",null,(0,r.kt)("strong",{parentName:"p"},"Fake-kubelet")," is a tool used to simulate any number of nodes and maintain pods on those nodes. It only does the minimum work of maintaining nodes and pods, so that it is very suitable for simulating a large number of nodes and pods for pressure testing on the control plane."),(0,r.kt)("h4",{id:"usage-1"},"Usage"),(0,r.kt)("p",null,"Deploy the fake-kubelet:"),(0,r.kt)("blockquote",null,(0,r.kt)("p",{parentName:"blockquote"},"Note:  Set container ENV ",(0,r.kt)("inlineCode",{parentName:"p"},"GENERATE_REPLICAS")," in fake-kubelet deployment to set node replicas you want to create")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-shell"},'export GENERATE_REPLICAS=your_replicas\ncurl https://raw.githubusercontent.com/wzshiming/fake-kubelet/master/deploy.yaml > fakekubelet.yml\n# GENERATE_REPLICAS default value is 5000\nsed -i "s/5000/$GENERATE_REPLICAS/g" fakekubelet.yml \nkubectl apply -f fakekubelet.yml\n')),(0,r.kt)("p",null,(0,r.kt)("inlineCode",{parentName:"p"},"kubectl get node")," You will find fake nodes."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-shell"},"> kubectl get node -o wide\nNAME         STATUS   ROLES   AGE   VERSION   INTERNAL-IP   EXTERNAL-IP   OS-IMAGE    KERNEL-VERSION   CONTAINER-RUNTIME\nfake-0       Ready    agent   10s   fake      10.88.0.136   <none>        <unknown>   <unknown>        <unknown>\nfake-1       Ready    agent   10s   fake      10.88.0.136   <none>        <unknown>   <unknown>        <unknown>\nfake-2       Ready    agent   10s   fake      10.88.0.136   <none>        <unknown>   <unknown>        <unknown>\nfake-3       Ready    agent   10s   fake      10.88.0.136   <none>        <unknown>   <unknown>        <unknown>\nfake-4       Ready    agent   10s   fake      10.88.0.136   <none>        <unknown>   <unknown>        <unknown>\n")),(0,r.kt)("p",null,"Deploy an sample deployment to test:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-shell"},'> kubectl apply -f - <<EOF\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: fake-pod\n  namespace: default\nspec:\n  replicas: 4\n  selector:\n    matchLabels:\n      app: fake-pod\n  template:\n    metadata:\n      labels:\n        app: fake-pod\n    spec:\n      affinity:\n        nodeAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n            nodeSelectorTerms:\n              - matchExpressions:\n                  - key: type\n                    operator: In\n                    values:\n                      - fake-kubelet\n      tolerations: # A taints was added to an automatically created Node. You can remove taints of Node or add this tolerations\n        - key: "fake-kubelet/provider"\n          operator: "Exists"\n          effect: "NoSchedule"\n      # nodeName: fake-0 # Or direct scheduling to a fake node\n      containers:\n        - name: fake-pod\n          image: fake\nEOF\n')),(0,r.kt)("p",null,(0,r.kt)("inlineCode",{parentName:"p"},"kubectl get pod")," You will find that it has been started, although the image does not exist."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-shell"},"> kubectl get pod -o wide\nNAME                        READY   STATUS    RESTARTS   AGE   IP          NODE     NOMINATED NODE   READINESS GATES\nfake-pod-78884479b7-52qcx   1/1     Running   0          6s    10.0.0.23   fake-4   <none>           <none>\nfake-pod-78884479b7-bd6nk   1/1     Running   0          6s    10.0.0.13   fake-2   <none>           <none>\nfake-pod-78884479b7-dqjtn   1/1     Running   0          6s    10.0.0.15   fake-2   <none>           <none>\nfake-pod-78884479b7-h2fv6   1/1     Running   0          6s    10.0.0.31   fake-0   <none>           <none>\n")),(0,r.kt)("h2",{id:"distribute-resources-using-clusterloader2"},"Distribute resources using CLusterLoader2"),(0,r.kt)("h3",{id:"clusterloader2"},"ClusterLoader2"),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/kubernetes/perf-tests/tree/master/clusterloader2"},"ClusterLoader2")," is an open source Kubernetes cluster testing tool. It tests against Kubernetes-defined SLIs/SLOs metrics to verify that clusters meet various quality of service standards. ClusterLoader2 is a tool oriented single cluster, it is complex to test karmada control plane meanwhile distribute resouces to member clusters. Therefore, we just use the ClusterLoader2 to distribute resources to clusters managed by karmada."),(0,r.kt)("h3",{id:"prepare-a-simple-config"},"Prepare a simple config"),(0,r.kt)("p",null,"Let's prepare our config (config.yaml) to distribute resources. This config will:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"Create 10 namespace")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"Create 20 deployments with 1000 pods inside that namespace"))),(0,r.kt)("p",null,"We will create file ",(0,r.kt)("inlineCode",{parentName:"p"},"config.yaml")," that describes this test. First we need to start with defining test name:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-yaml"},"name: test\n")),(0,r.kt)("p",null,"ClusterLoader2 will create namespaces automatically, but we need to specify how many namespaces we want:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-yaml"},"namespace:\n  number: 10\n")),(0,r.kt)("p",null,"Next, we need to specify TuningSets. TuningSet describes how actions are executed. The qps means 1/qps s per action interval. In order to distribute resources slowly to relieve the pressure on the apiserver, the qps of Uniformtinyqps is set to 0.1, which means that after distributing a deployment, we wait 10s before continuing to distribute the next deployment."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-yaml"},"tuningSets:\n- name: Uniformtinyqps\n    qpsLoad:\n      qps: 0.1\n- name: Uniform1qps\n    qpsLoad:\n      qps: 1\n")),(0,r.kt)("p",null,"Finally, we will create a phase that creates deployment and propagation policy. We need to specify in which namespaces we want the deployment and propagation policy to be created, how many of these deployments per namespace. Also, we will need to specify template for our deployment and propagation policy , which we will do later. For now, let's assume that this template allows us to specify numbers of replicas in deployment and propagation policy."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-yaml"},'steps:\n- name: Create deployment\n  phases:\n  - namespaceRange:\n      min: 1\n      max: 10\n    replicasPerNamespace: 20\n    tuningSet: Uniformtinyqps\n    objectBundle:\n    - basename: test-deployment\n      objectTemplatePath: "deployment.yaml"\n      templateFillMap:\n        Replicas: 1000\n  - namespaceRange:\n      min: 1\n      max: 10\n    replicasPerNamespace: 1\n    tuningSet: Uniform1qps\n    - basename: test-policy\n      objectTemplatePath: "policy.yaml"\n      templateFillMap:\n        Replicas: 1\n        \n')),(0,r.kt)("p",null,"THe whole ",(0,r.kt)("inlineCode",{parentName:"p"},"config.yaml")," will look like this:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-yaml"},'name: test\n\nnamespace:\n  number: 10\n\ntuningSets:\n- name: Uniformtinyqps\n    qpsLoad:\n    qps: 0.1\n- name: Uniform1qps\n  qpsLoad:\n    qps: 1\n\nsteps:\n- name: Create deployment \n  phases:\n  - namespaceRange:\n      min: 1\n      max: 10\n    replicasPerNamespace: 20\n    tuningSet: Uniformtinyqps\n    objectBundle:\n    - basename: test-deployment\n      objectTemplatePath: "deployment.yaml"\n      templateFillMap:\n        Replicas: 1000\n  - namespaceRange:\n      min: 1\n      max: 10\n    replicasPerNamespace: 1\n    tuningSet: Uniform1qps\n    objectBundle:\n    - basename: test-policy\n      objectTemplatePath: "policy.yaml"\n')),(0,r.kt)("p",null,"Now, we need to specify deployment and propagation template. ClusterLoader2 by default adds parameter ",(0,r.kt)("inlineCode",{parentName:"p"},"Name")," that you can use in your template. In our config, we also passed ",(0,r.kt)("inlineCode",{parentName:"p"},"Replicas")," parameter. So our template for deployment and propagation policy will look like following:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-yaml"},'# deployment.yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: {{.Name}}\n  labels:\n    group: test-deployment\nspec:\n  replicas: {{.Replicas}}\n  selector:\n    matchLabels:\n      app: fake-pod\n  template:\n    metadata:\n      labels:\n        app: fake-pod\n    spec:\n      affinity:\n        nodeAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n            nodeSelectorTerms:\n              - matchExpressions:\n                  - key: type\n                    operator: In\n                    values:\n                      - fake-kubelet\n      tolerations: # A taints was added to an automatically created Node. You can remove taints of Node or add this tolerations\n          - key: "fake-kubelet/provider"\n            operator: "Exists"\n            effect: "NoSchedule"\n      containers:\n        - image: fake-pod\n          name: {{.Name}}\n')),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-yaml"},"# policy.yaml\napiVersion: policy.karmada.io/v1alpha1\nkind: PropagationPolicy\nmetadata:\n  name: test\nspec:\n  resourceSelectors:\n    - apiVersion: apps/v1\n      kind: Deployment\n  placement:\n    replicaScheduling:\n      replicaDivisionPreference: Weighted\n      replicaSchedulingType: Divided\n")),(0,r.kt)("h3",{id:"start-distributing"},"Start Distributing"),(0,r.kt)("p",null,"To distributing resources,  run:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-shell"},"export KARMADA_APISERVERCONFIG=your_config\nexport KARMADA-APISERVERIP=your_ip\ncd clusterloader2/\ngo run cmd/clusterloader.go --testconfig=config.yaml --provider=local --kubeconfig=$KARMADA_APISERVERCONFIG --v=2 --k8s-clients-number=1 --skip-cluster-verification=true --masterip=$KARMADA-APISERVERIP --enable-exec-service=false\n")),(0,r.kt)("p",null,"The meaning of args above shows as following:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"k8s-clients-number: the number of karmada apiserver client number."),(0,r.kt)("li",{parentName:"ul"},"skip-cluster-verification: whether to skip the cluster verification, which expects at least one schedulable node in the cluster."),(0,r.kt)("li",{parentName:"ul"},"enable-exec-service: whether to enable exec service that allows executing arbitrary commands from a pod running in the cluster.")),(0,r.kt)("p",null,"Since the resources of member cluster cannot be accessed in karmada control plane, we have to turn off enable-exec-service and cluster-verification."),(0,r.kt)("h2",{id:"monitor-karmada-control-plane-using-prometheus-and-grafana"},"Monitor Karmada control plane using Prometheus and Grafana"),(0,r.kt)("h3",{id:"deploy-prometheus-and-grafana"},"Deploy Prometheus and Grafana"),(0,r.kt)("blockquote",null,(0,r.kt)("p",{parentName:"blockquote"},"Follow the ",(0,r.kt)("a",{parentName:"p",href:"https://karmada.io/docs/administrator/monitoring/working-with-prometheus-in-control-plane"},"Prometheus and Grafana Deploy Guide"))),(0,r.kt)("h3",{id:"create-grafana-dashboards-to-observe-karmada-control-plane-metrics"},"Create Grafana DashBoards to observe Karmada control plane metrics"),(0,r.kt)("p",null,"Here's an example to monitor the mutating api call latency for works and resourcebindings of the karmada apiserver through grafana. Monitor the metrics you want by modifying the Query statement."),(0,r.kt)("h4",{id:"create-a-dashboard"},"Create a dashboard"),(0,r.kt)("blockquote",null,(0,r.kt)("p",{parentName:"blockquote"},"Follw the ",(0,r.kt)("a",{parentName:"p",href:"https://prometheus.io/docs/visualization/grafana/"},"Grafana support For Prometheus"),"  document.")),(0,r.kt)("h4",{id:"modify-query-statement"},"Modify Query Statement"),(0,r.kt)("p",null,"Enter the following Prometheus expression into the ",(0,r.kt)("inlineCode",{parentName:"p"}," Query")," field."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-sql"},'histogram_quantile(0.99, sum(rate(apiserver_request_duration_seconds_bucket{verb!="WATCH|GET|LIST", resource~="works|resourcebindings"}[5m])) by (resource, verb, le))\n')),(0,r.kt)("p",null,"The gragh will show as follow:"),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"grafana-dashboard",src:t(2336).Z,width:"910",height:"332"})))}d.isMDXComponent=!0},2336:(e,n,t)=>{t.d(n,{Z:()=>a});const a=t.p+"assets/images/grafana_metrics-00edbc0b08dfd080833d9c488c585599.png"}}]);